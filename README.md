# Generative-Adversarial-Network-1-D
Design a generator G that generates data from a desired distribution using multi-layer perceptron (only fully connected layers with non-linearities) which takes a single scalar z as input and outputs a single scalar x. You can use ReLU as the non-linear activation function for the hidden layers, and the output layer does not have any activations. Complement the generator G with a discriminator D for an adversarial training which also uses multi-layer perceptron (only fully connected layer with non-linearities). D takes a single scalar x or xdata as input and outputs a [0,1] value for classification; x is the output from G and xdata is a sample from the desired data distribution. You can use ReLU/Tanh as the non-linear activation function for hidden layers and sigmoid for the output layer. Some tips are given below, but the final choice and tuning is up to the student: ffl The choice of the number of hidden layers is yours; you can try two or three hidden layers for both G and D.
